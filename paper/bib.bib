@misc{zhao2023survey,
      title={A Survey of Large Language Models}, 
      author={Wayne Xin Zhao and Kun Zhou and Junyi Li and Tianyi Tang and Xiaolei Wang and Yupeng Hou and Yingqian Min and Beichen Zhang and Junjie Zhang and Zican Dong and Yifan Du and Chen Yang and Yushuo Chen and Zhipeng Chen and Jinhao Jiang and Ruiyang Ren and Yifan Li and Xinyu Tang and Zikang Liu and Peiyu Liu and Jian-Yun Nie and Ji-Rong Wen},
      year={2023},
      eprint={2303.18223},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}


@article{Sarker2021,
  doi = {10.1007/s42979-021-00815-1},
  url = {https://doi.org/10.1007/s42979-021-00815-1},
  year = {2021},
  month = aug,
  publisher = {Springer Science and Business Media {LLC}},
  volume = {2},
  number = {6},
  author = {Iqbal H. Sarker},
  title = {Deep Learning: A Comprehensive Overview on Techniques,  Taxonomy,  Applications and Research Directions},
  journal = {{SN} Computer Science}
}

@misc{Dosovitskiy2020,
  doi = {10.48550/ARXIV.2010.11929},
  url = {https://arxiv.org/abs/2010.11929},
  author = {Dosovitskiy,  Alexey and Beyer,  Lucas and Kolesnikov,  Alexander and Weissenborn,  Dirk and Zhai,  Xiaohua and Unterthiner,  Thomas and Dehghani,  Mostafa and Minderer,  Matthias and Heigold,  Georg and Gelly,  Sylvain and Uszkoreit,  Jakob and Houlsby,  Neil},
  keywords = {Computer Vision and Pattern Recognition (cs.CV),  Artificial Intelligence (cs.AI),  Machine Learning (cs.LG),  FOS: Computer and information sciences,  FOS: Computer and information sciences},
  title = {An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale},
  publisher = {arXiv},
  year = {2020},
  copyright = {arXiv.org perpetual,  non-exclusive license}
}

@misc{Raj2023,
      title={Measuring Reliability of Large Language Models through Semantic Consistency}, 
      author={Harsh Raj and Domenic Rosati and Subhabrata Majumdar},
      year={2023},
      eprint={2211.05853},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{Ruis2023,
title={Large language models are not zero-shot communicators},
author={Laura Eline Ruis and Akbir Khan and Stella Biderman and Sara Hooker and Tim Rockt{\"a}schel and Edward Grefenstette},
year={2023},
url={https://openreview.net/forum?id=WgbcOQMNXB}
}

@inproceedings{Eiter2009,
author = {Eiter, Thomas and Ianni, Giovambattista and Krennwallner, Thomas},
year = {2009},
month = {01},
pages = {40-110},
title = {Answer Set Programming: A Primer},
volume = {5689},
isbn = {978-3-642-03753-5},
journal = {Lecture Notes in Computer Science},
doi = {10.1007/978-3-642-03754-2_2}
}
@article{Gelfond2000,
author = {Gelfond, Michael and Lifschitz, Vladimir},
year = {2000},
month = {12},
pages = {},
title = {The Stable Model Semantics For Logic Programming},
volume = {2},
journal = {Logic Programming}
}

@incollection{Gelfond2002,
  doi = {10.1007/3-540-45632-5_16},
  url = {https://doi.org/10.1007/3-540-45632-5_16},
  year = {2002},
  publisher = {Springer Berlin Heidelberg},
  pages = {413--451},
  author = {Michael Gelfond},
  title = {Representing Knowledge in A-Prolog},
  booktitle = {Computational Logic: Logic Programming and Beyond}
}

@book{Gebser2013,
  doi = {10.1007/978-3-031-01561-8},
  url = {https://doi.org/10.1007/978-3-031-01561-8},
  year = {2013},
  publisher = {Springer International Publishing},
  author = {Martin Gebser and Roland Kaminski and Benjamin Kaufmann and Torsten Schaub},
  title = {Answer Set Solving in Practice}
}

@misc{Gebser2014,
      title={Clingo = ASP + Control: Preliminary Report}, 
      author={Martin Gebser and Roland Kaminski and Benjamin Kaufmann and Torsten Schaub},
      year={2014},
      eprint={1405.3694},
      archivePrefix={arXiv},
      primaryClass={cs.PL}
}

@inproceedings{Xia2020,
author = {Xia, Boming and Ye, Xiaozhen and Abuassba, Adnan},
year = {2020},
month = {06},
pages = {505-510},
title = {Recent Research on AI in Games},
doi = {10.1109/IWCMC48107.2020.9148327}
}

@inproceedings{Holldobler2014,
author = {Hölldobler, Steffen and Schweizer, Lukas},
year = {2014},
month = {04},
pages = {},
title = {Answer set programming and CLASP: A tutorial},
volume = {1145},
journal = {CEUR Workshop Proceedings}
}

@inproceedings{Vaswani2017,
 author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, \L ukasz and Polosukhin, Illia},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {I. Guyon and U. Von Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Attention is All you Need},
 url = {https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf},
 volume = {30},
 year = {2017}
}

@misc{Bommasani2021,
  doi = {10.48550/ARXIV.2108.07258},
  url = {https://arxiv.org/abs/2108.07258},
  author = {Bommasani,  Rishi and Hudson,  Drew A. and Adeli,  Ehsan and Altman,  Russ and Arora,  Simran and von Arx,  Sydney and Bernstein,  Michael S. and Bohg,  Jeannette and Bosselut,  Antoine and Brunskill,  Emma and Brynjolfsson,  Erik and Buch,  Shyamal and Card,  Dallas and Castellon,  Rodrigo and Chatterji,  Niladri and Chen,  Annie and Creel,  Kathleen and Davis,  Jared Quincy and Demszky,  Dora and Donahue,  Chris and Doumbouya,  Moussa and Durmus,  Esin and Ermon,  Stefano and Etchemendy,  John and Ethayarajh,  Kawin and Fei-Fei,  Li and Finn,  Chelsea and Gale,  Trevor and Gillespie,  Lauren and Goel,  Karan and Goodman,  Noah and Grossman,  Shelby and Guha,  Neel and Hashimoto,  Tatsunori and Henderson,  Peter and Hewitt,  John and Ho,  Daniel E. and Hong,  Jenny and Hsu,  Kyle and Huang,  Jing and Icard,  Thomas and Jain,  Saahil and Jurafsky,  Dan and Kalluri,  Pratyusha and Karamcheti,  Siddharth and Keeling,  Geoff and Khani,  Fereshte and Khattab,  Omar and Koh,  Pang Wei and Krass,  Mark and Krishna,  Ranjay and Kuditipudi,  Rohith and Kumar,  Ananya and Ladhak,  Faisal and Lee,  Mina and Lee,  Tony and Leskovec,  Jure and Levent,  Isabelle and Li,  Xiang Lisa and Li,  Xuechen and Ma,  Tengyu and Malik,  Ali and Manning,  Christopher D. and Mirchandani,  Suvir and Mitchell,  Eric and Munyikwa,  Zanele and Nair,  Suraj and Narayan,  Avanika and Narayanan,  Deepak and Newman,  Ben and Nie,  Allen and Niebles,  Juan Carlos and Nilforoshan,  Hamed and Nyarko,  Julian and Ogut,  Giray and Orr,  Laurel and Papadimitriou,  Isabel and Park,  Joon Sung and Piech,  Chris and Portelance,  Eva and Potts,  Christopher and Raghunathan,  Aditi and Reich,  Rob and Ren,  Hongyu and Rong,  Frieda and Roohani,  Yusuf and Ruiz,  Camilo and Ryan,  Jack and Ré,  Christopher and Sadigh,  Dorsa and Sagawa,  Shiori and Santhanam,  Keshav and Shih,  Andy and Srinivasan,  Krishnan and Tamkin,  Alex and Taori,  Rohan and Thomas,  Armin W. and Tramèr,  Florian and Wang,  Rose E. and Wang,  William and Wu,  Bohan and Wu,  Jiajun and Wu,  Yuhuai and Xie,  Sang Michael and Yasunaga,  Michihiro and You,  Jiaxuan and Zaharia,  Matei and Zhang,  Michael and Zhang,  Tianyi and Zhang,  Xikun and Zhang,  Yuhui and Zheng,  Lucia and Zhou,  Kaitlyn and Liang,  Percy},
  keywords = {Machine Learning (cs.LG),  Artificial Intelligence (cs.AI),  Computers and Society (cs.CY),  FOS: Computer and information sciences,  FOS: Computer and information sciences},
  title = {On the Opportunities and Risks of Foundation Models},
  publisher = {arXiv},
  year = {2021},
  copyright = {Creative Commons Attribution 4.0 International}
}


@misc{Paranjape2023,
      title={ART: Automatic multi-step reasoning and tool-use for large language models}, 
      author={Bhargavi Paranjape and Scott Lundberg and Sameer Singh and Hannaneh Hajishirzi and Luke Zettlemoyer and Marco Tulio Ribeiro},
      year={2023},
      eprint={2303.09014},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{Vinarti2019,
  doi = {10.1016/j.procs.2019.11.188},
  url = {https://doi.org/10.1016/j.procs.2019.11.188},
  year = {2019},
  publisher = {Elsevier {BV}},
  volume = {161},
  pages = {821--825},
  author = {Retno Aulia Vinarti},
  title = {Knowledge Representation for Infectious Disease Risk Prediction System: A Literature Review},
  journal = {Procedia Computer Science}
}

@misc{bowman2023things,
      title={{Eight Things to Know about Large Language Models}}, 
      author={Samuel R. Bowman},
      year={2023},
      eprint={2304.00612},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{liu2021pretrain,
      title={Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing}, 
      author={Pengfei Liu and Weizhe Yuan and Jinlan Fu and Zhengbao Jiang and Hiroaki Hayashi and Graham Neubig},
      year={2021},
      eprint={2107.13586},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{promptingguidePromptEngineering,
	author = {},
	title = {{P}rompt {E}ngineering {G}uide},
	howpublished = {\url{https://www.promptingguide.ai}},
	year = {},
	note = {[Accessed 27-May-2023]},
}

@article{Erdem2011,
  doi = {10.1609/aaai.v25i1.7946},
  url = {https://doi.org/10.1609/aaai.v25i1.7946},
  year = {2011},
  month = aug,
  publisher = {Association for the Advancement of Artificial Intelligence ({AAAI})},
  volume = {25},
  number = {1},
  pages = {785--790},
  author = {Esra Erdem and Yelda Erdem and Halit Erdogan and Umut Oztok},
  title = {Finding Answers and Generating Explanations for Complex Biomedical Queries},
  journal = {Proceedings of the {AAAI} Conference on Artificial Intelligence}
}

@article{Cabalar_2020,
	doi = {10.4204/eptcs.325.19},
	url = {https://doi.org/10.4204\%2Feptcs.325.19},
	year = 2020,
	month = {sep},
	publisher = {Open Publishing Association},
	volume = {325},
	pages = {124--136},
	author = {Pedro Cabalar and Jorge Fandinno and Brais Mu{\~{n}}iz},
	title={{{A System for Explainable Answer Set Programming}}},
	journal = {Electronic Proceedings in Theoretical Computer Science}
}

@misc{ré2014feature,
      title={Feature Engineering for Knowledge Base Construction}, 
      author={Christopher Ré and Amir Abbas Sadeghian and Zifei Shan and Jaeho Shin and Feiran Wang and Sen Wu and Ce Zhang},
      year={2014},
      eprint={1407.6439},
      archivePrefix={arXiv},
      primaryClass={cs.DB}
}

@misc{migraine-hives,
  title = {Migraine Hives Symptoms},
  author = {{Migraine.com Editorial Team}},
  howpublished = {\url{https://migraine.com/migraine-symptoms/hives}},
  note = {Accessed on May 30, 2023}
}

@misc{cabalar2014causal,
      title={Causal Graph Justifications of Logic Programs}, 
      author={Pedro Cabalar and Jorge Fandinno and Michael Fink},
      year={2014},
      eprint={1409.7281},
      archivePrefix={arXiv},
      primaryClass={cs.AI}
}

@article{Alviano_2020,
    author={Alviano, Mario and Bertolucci, Riccardo and Cardellini, Valeria and Dodaro, Carmine and Galatà, Giuseppe and Khan, Muhammad Kashif and Leone, Nicola and Maratea, Marco and Ricca, Francesco and Schouten, Marco},
    title={Answer Set Programming in Healthcare: Extended Overview},
    year={2020},
    url={http://ceur-ws.org/Vol-2745/paper7.pdf},
    journal={IPS-RCRA@ AI* IA},
    publisher={CEUR-WS.org},
}


@misc{openai2023gpt4,
      title={GPT-4 Technical Report}, 
      author={OpenAI},
      year={2023},
      eprint={2303.08774},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
@misc{gpt5,
      title={GPT-5}, 
      author={OpenAI},
      year={2025},
      url={https://openai.com/gpt-5/},
}

@inproceedings{gel88,
title={The Stable Model Semantics for Logic Programming},
author={Michael Gelfond and Vladimir Lifschitz},
booktitle={Proceedings of International Logic Programming Conference and Symposium},
editor={Kowalski, Robert and Bowen and Kenneth},
publisher={MIT Press},
pages={1070-1080},
url="http://www.cs.utexas.edu/users/ai-lab?gel88",
year={1988}
}

@article{Brewka2011,
author = {Brewka, Gerhard and Eiter, Thomas and Truszczy\'{n}ski, Miros\l{}aw},
title = {Answer set programming at a glance},
year = {2011},
issue_date = {December 2011},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {54},
number = {12},
issn = {0001-0782},
url = {https://doi.org/10.1145/2043174.2043195},
doi = {10.1145/2043174.2043195},
abstract = {The motivation and key concepts behind answer set programming---a promising approach to declarative problem solving.},
journal = {Commun. ACM},
month = dec,
pages = {92–103},
numpages = {12}
}

@misc{Dodge2021,
      title={Documenting Large Webtext Corpora: A Case Study on the Colossal Clean Crawled Corpus}, 
      author={Jesse Dodge and Maarten Sap and Ana Marasović and William Agnew and Gabriel Ilharco and Dirk Groeneveld and Margaret Mitchell and Matt Gardner},
      year={2021},
      eprint={2104.08758},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2104.08758}, 
}

@inproceedings{Brown2020,
 author = {Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and Agarwal, Sandhini and Herbert-Voss, Ariel and Krueger, Gretchen and Henighan, Tom and Child, Rewon and Ramesh, Aditya and Ziegler, Daniel and Wu, Jeffrey and Winter, Clemens and Hesse, Chris and Chen, Mark and Sigler, Eric and Litwin, Mateusz and Gray, Scott and Chess, Benjamin and Clark, Jack and Berner, Christopher and McCandlish, Sam and Radford, Alec and Sutskever, Ilya and Amodei, Dario},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Larochelle and M. Ranzato and R. Hadsell and M.F. Balcan and H. Lin},
 pages = {1877--1901},
 publisher = {Curran Associates, Inc.},
 title = {Language Models are Few-Shot Learners},
 url = {https://proceedings.neurips.cc/paper_files/paper/2020/file/1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf},
 volume = {33},
 year = {2020}
}


@InProceedings{Zhang2020,
  title = 	 {{PEGASUS}: Pre-training with Extracted Gap-sentences for Abstractive Summarization},
  author =       {Zhang, Jingqing and Zhao, Yao and Saleh, Mohammad and Liu, Peter},
  booktitle = 	 {Proceedings of the 37th International Conference on Machine Learning},
  pages = 	 {11328--11339},
  year = 	 {2020},
  editor = 	 {III, Hal Daumé and Singh, Aarti},
  volume = 	 {119},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {13--18 Jul},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v119/zhang20ae/zhang20ae.pdf},
  url = 	 {https://proceedings.mlr.press/v119/zhang20ae.html},
  abstract = 	 {Recent work pre-training Transformers with self-supervised objectives on large text corpora has shown great success when fine-tuned on downstream NLP tasks including text summarization. However, pre-training objectives tailored for abstractive text summarization have not been explored. Furthermore there is a lack of systematic evaluation across diverse domains. In this work, we propose pre-training large Transformer-based encoder-decoder models on massive text corpora with a new self-supervised objective. In PEGASUS, important sentences are removed/masked from an input document and are generated together as one output sequence from the remaining sentences, similar to an extractive summary. We evaluated our best PEGASUS model on 12 downstream summarization tasks spanning news, science, stories, instructions, emails, patents, and legislative bills. Experiments demonstrate it achieves state-of-the-art performance on all 12 downstream datasets measured by ROUGE scores. Our model also shows surprising performance on low-resource summarization, surpassing previous state-of-the-art results on 6 datasets with only 1000 examples. Finally we validated our results using human evaluation and show that our model summaries achieve human performance on multiple datasets.}
}

@misc{Thoppilan2022lamda,
      title={LaMDA: Language Models for Dialog Applications}, 
      author={Romal Thoppilan and Daniel De Freitas and Jamie Hall and Noam Shazeer and Apoorv Kulshreshtha and Heng-Tze Cheng and Alicia Jin and Taylor Bos and Leslie Baker and Yu Du and YaGuang Li and Hongrae Lee and Huaixiu Steven Zheng and Amin Ghafouri and Marcelo Menegali and Yanping Huang and Maxim Krikun and Dmitry Lepikhin and James Qin and Dehao Chen and Yuanzhong Xu and Zhifeng Chen and Adam Roberts and Maarten Bosma and Vincent Zhao and Yanqi Zhou and Chung-Ching Chang and Igor Krivokon and Will Rusch and Marc Pickett and Pranesh Srinivasan and Laichee Man and Kathleen Meier-Hellstern and Meredith Ringel Morris and Tulsee Doshi and Renelito Delos Santos and Toju Duke and Johnny Soraker and Ben Zevenbergen and Vinodkumar Prabhakaran and Mark Diaz and Ben Hutchinson and Kristen Olson and Alejandra Molina and Erin Hoffman-John and Josh Lee and Lora Aroyo and Ravi Rajakumar and Alena Butryna and Matthew Lamm and Viktoriya Kuzmina and Joe Fenton and Aaron Cohen and Rachel Bernstein and Ray Kurzweil and Blaise Aguera-Arcas and Claire Cui and Marian Croak and Ed Chi and Quoc Le},
      year={2022},
      eprint={2201.08239},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2201.08239}, 
}

@misc{Chen2021,
      title={Evaluating Large Language Models Trained on Code}, 
      author={Mark Chen and Jerry Tworek and Heewoo Jun and Qiming Yuan and Henrique Ponde de Oliveira Pinto and Jared Kaplan and Harri Edwards and Yuri Burda and Nicholas Joseph and Greg Brockman and Alex Ray and Raul Puri and Gretchen Krueger and Michael Petrov and Heidy Khlaaf and Girish Sastry and Pamela Mishkin and Brooke Chan and Scott Gray and Nick Ryder and Mikhail Pavlov and Alethea Power and Lukasz Kaiser and Mohammad Bavarian and Clemens Winter and Philippe Tillet and Felipe Petroski Such and Dave Cummings and Matthias Plappert and Fotios Chantzis and Elizabeth Barnes and Ariel Herbert-Voss and William Hebgen Guss and Alex Nichol and Alex Paino and Nikolas Tezak and Jie Tang and Igor Babuschkin and Suchir Balaji and Shantanu Jain and William Saunders and Christopher Hesse and Andrew N. Carr and Jan Leike and Josh Achiam and Vedant Misra and Evan Morikawa and Alec Radford and Matthew Knight and Miles Brundage and Mira Murati and Katie Mayer and Peter Welinder and Bob McGrew and Dario Amodei and Sam McCandlish and Ilya Sutskever and Wojciech Zaremba},
      year={2021},
      eprint={2107.03374},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2107.03374}, 
}

@misc{Singhal2023,
      title={Towards Expert-Level Medical Question Answering with Large Language Models}, 
      author={Karan Singhal and Tao Tu and Juraj Gottweis and Rory Sayres and Ellery Wulczyn and Le Hou and Kevin Clark and Stephen Pfohl and Heather Cole-Lewis and Darlene Neal and Mike Schaekermann and Amy Wang and Mohamed Amin and Sami Lachgar and Philip Mansfield and Sushant Prakash and Bradley Green and Ewa Dominowska and Blaise Aguera y Arcas and Nenad Tomasev and Yun Liu and Renee Wong and Christopher Semturs and S. Sara Mahdavi and Joelle Barral and Dale Webster and Greg S. Corrado and Yossi Matias and Shekoofeh Azizi and Alan Karthikesalingam and Vivek Natarajan},
      year={2023},
      eprint={2305.09617},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2305.09617}, 
}

@article{Luo2022,
   title={BioGPT: generative pre-trained transformer for biomedical text generation and mining},
   volume={23},
   ISSN={1477-4054},
   url={http://dx.doi.org/10.1093/bib/bbac409},
   DOI={10.1093/bib/bbac409},
   number={6},
   journal={Briefings in Bioinformatics},
   publisher={Oxford University Press (OUP)},
   author={Luo, Renqian and Sun, Liai and Xia, Yingce and Qin, Tao and Zhang, Sheng and Poon, Hoifung and Liu, Tie-Yan},
   year={2022},
   month=sep 
}

@misc{Ganguli2022,
      title={Red Teaming Language Models to Reduce Harms: Methods, Scaling Behaviors, and Lessons Learned}, 
      author={Deep Ganguli and Liane Lovitt and Jackson Kernion and Amanda Askell and Yuntao Bai and Saurav Kadavath and Ben Mann and Ethan Perez and Nicholas Schiefer and Kamal Ndousse and Andy Jones and Sam Bowman and Anna Chen and Tom Conerly and Nova DasSarma and Dawn Drain and Nelson Elhage and Sheer El-Showk and Stanislav Fort and Zac Hatfield-Dodds and Tom Henighan and Danny Hernandez and Tristan Hume and Josh Jacobson and Scott Johnston and Shauna Kravec and Catherine Olsson and Sam Ringer and Eli Tran-Johnson and Dario Amodei and Tom Brown and Nicholas Joseph and Sam McCandlish and Chris Olah and Jared Kaplan and Jack Clark},
      year={2022},
      eprint={2209.07858},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2209.07858}, 
}

@inproceedings{Nguyen2025,
author = {Nguyen, Quang-Anh and Pham, Thu-Trang and Vuong, Thi-Hai-yen and Trinh, Giang and Thanh, Nguyen},
year = {2025},
month = {01},
pages = {1327-1334},
title = {Detecting Misleading Information with LLMs and Explainable ASP},
doi = {10.5220/0013357400003890}
}

@inproceedings{alviano2024llm2asp,
  author    = {Mario Alviano and Luca Grillo},
  title     = {Answer Set Programming and Large Language Models Interaction with YAML: Preliminary Report},
  booktitle = {Proceedings of the 39th Italian Conference on Computational Logic (CILC 2024)},
  series    = {CEUR Workshop Proceedings},
  volume    = {3733},
  year      = {2024},
  publisher = {CEUR-WS.org},
  url       = {https://ceur-ws.org/Vol-3733/short2.pdf}
}


@misc{coppolillo2024llasp,
      title={LLASP: Fine-tuning Large Language Models for Answer Set Programming}, 
      author={Erica Coppolillo and Francesco Calimeri and Giuseppe Manco and Simona Perri and Francesco Ricca},
      year={2024},
      eprint={2407.18723},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2407.18723}, 
}

@inproceedings{alviano2024answer,
  title={Answer Set Programming and Large Language Models interaction with YAML: Preliminary Report},
  author={Alviano, Mario and Grillo, Lorenzo and others},
  booktitle={CILC, CEUR Workshop Proceedings, CEUR-WS. org},
  year={2024}
}

@article{CHEN_2016,
   title={A Physician Advisory System for Chronic Heart Failure management based on knowledge patterns},
   volume={16},
   ISSN={1475-3081},
   url={http://dx.doi.org/10.1017/S1471068416000429},
   DOI={10.1017/s1471068416000429},
   number={5–6},
   journal={Theory and Practice of Logic Programming},
   publisher={Cambridge University Press (CUP)},
   author={CHEN, ZHUO and MARPLE, KYLE and SALAZAR, ELMER and GUPTA, GOPAL and TAMIL, LAKSHMAN},
   year={2016},
   month=sep, pages={604–618} }

@article{marple2017s,
  title={The s (ASP) predicate answer set programming system},
  author={Marple, Kyle and Salazar, Elmer and Chen, Zhuo and Gupta, Gopal},
  journal={The Association for Logic Programming Newsletter},
  year={2017}
}

@article{chen2018automating,
  title={Automating disease management using answer set programming},
  author={Chen, Zhuo},
  year={2018},
  publisher={Dagstuhl Publishing}
}

@book{Gelfond_Kahl_2014, 
      place={Cambridge}, 
      title={Knowledge Representation, Reasoning, and the Design of Intelligent Agents: The Answer-Set Programming Approach}, 
      publisher={Cambridge University Press}, 
      author={Gelfond, Michael and Kahl, Yulia}, 
      year={2014}
} 

@article{Singhal2022LargeLM,
  title={Large language models encode clinical knowledge},
  author={K. Singhal and Shekoofeh Azizi and Tao Tu and Said Mahdavi and Jason Wei and Hyung Won Chung and Nathan Scales and Ajay Kumar Tanwani and Heather J. Cole-Lewis and Stephen J. Pfohl and P A Payne and Martin G. Seneviratne and Paul Gamble and Chris Kelly and Nathaneal Scharli and Aakanksha Chowdhery and P. A. Mansfield and Blaise Ag{\"u}era y Arcas and Dale R. Webster and Greg S. Corrado and Yossi Matias and Katherine Hui-Ling Chou and Juraj Gottweis and Nenad Tomaev and Yun Liu and Alvin Rajkomar and Jo{\"e}lle K. Barral and Christopher Semturs and Alan Karthikesalingam and Vivek Natarajan},
  journal={Nature},
  year={2022},
  volume={620},
  pages={172 - 180},
  url={https://api.semanticscholar.org/CorpusID:255124952}
}

@misc{Zheng2024LLMmed,
      title={Large Language Models for Medicine: A Survey}, 
      author={Yanxin Zheng and Wensheng Gan and Zefeng Chen and Zhenlian Qi and Qian Liang and Philip S. Yu},
      year={2024},
      eprint={2405.13055},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2405.13055}, 
}

@misc{aljohani2025comprehensivesurveytrustworthinesslarge,
      title={A Comprehensive Survey on the Trustworthiness of Large Language Models in Healthcare}, 
      author={Manar Aljohani and Jun Hou and Sindhura Kommu and Xuan Wang},
      year={2025},
      eprint={2502.15871},
      archivePrefix={arXiv},
      primaryClass={cs.CY},
      url={https://arxiv.org/abs/2502.15871}, 
}

@misc{rudin2019stopexplainingblackbox,
      title={Stop Explaining Black Box Machine Learning Models for High Stakes Decisions and Use Interpretable Models Instead}, 
      author={Cynthia Rudin},
      year={2019},
      eprint={1811.10154},
      archivePrefix={arXiv},
      primaryClass={stat.ML},
      url={https://arxiv.org/abs/1811.10154}, 
}